# Infrastructure Architecture Patterns

## Overview
Comprehensive analysis of Cloudflare Workers platform infrastructure including Workers, Durable Objects, deployment strategies, and configuration management for building scalable serverless applications.

## Table of Contents
1. [Cloudflare Workers Architecture](#cloudflare-workers-architecture)
2. [Durable Objects Patterns](#durable-objects-patterns)
3. [Deployment Configuration](#deployment-configuration)
4. [Environment Management](#environment-management)
5. [Workers for Platforms](#workers-for-platforms)
6. [Container Integration](#container-integration)
7. [Service Bindings](#service-bindings)

---

## Cloudflare Workers Architecture

### 1. Worker Configuration Structure

#### Wrangler Configuration Pattern
```jsonc
{
  "name": "stich-production",
  "main": "worker/index.ts",
  "compatibility_date": "2025-08-10",
  "compatibility_flags": ["nodejs_compat"],
  
  // Version metadata binding
  "version_metadata": {
    "binding": "CF_VERSION_METADATA"
  },
  
  // Static assets configuration
  "assets": {
    "directory": "dist",
    "not_found_handling": "single-page-application",
    "run_worker_first": true,
    "binding": "ASSETS"
  },
  
  // Observability and monitoring
  "observability": {
    "enabled": true,
    "head_sampling_rate": 1
  },
  
  // Rate limiting bindings
  "unsafe": {
    "bindings": [
      {
        "name": "API_RATE_LIMITER",
        "type": "ratelimit",
        "namespace_id": "2101",
        "simple": { "limit": 10000, "period": 60 }
      }
    ]
  }
}
```

#### Worker Entry Point Pattern
```typescript
// worker/index.ts
import { Hono } from 'hono';
import { cors } from 'hono/cors';
import { logger } from 'hono/logger';
import { sentryOptions } from './config/sentry';

// Environment type definitions
export interface Env extends Cloudflare.Env {
  // Database bindings
  DB: D1Database;
  
  // Storage bindings
  TEMPLATES_BUCKET: R2Bucket;
  VibecoderStore: KVNamespace;
  
  // Durable Object bindings
  CodeGenObject: DurableObjectNamespace<CodeGeneratorAgent>;
  Sandbox: DurableObjectNamespace<UserAppSandboxService>;
  DORateLimitStore: DurableObjectNamespace<DORateLimitStore>;
  
  // AI and Images bindings
  AI: Ai;
  IMAGES: Cloudflare.Images;
  
  // Workers for Platforms
  DISPATCHER: DispatchNamespace;
  
  // Environment variables
  GITHUB_CLIENT_ID: string;
  GITHUB_CLIENT_SECRET: string;
  JWT_SECRET: string;
  CUSTOM_DOMAIN: string;
  MAX_SANDBOX_INSTANCES: string;
}

// Main worker application
const app = new Hono<{ Bindings: Env }>();

// Global middleware
app.use('*', cors());
app.use('*', logger());

// Route handlers
app.route('/api/v1', apiRoutes);
app.get('*', serveStatic({ root: './' }));

export default app;

// Export Durable Object classes
export { CodeGeneratorAgent } from './agents/core/simpleGeneratorAgent';
export { UserAppSandboxService } from './services/sandbox/sandboxSdkClient';
export { DORateLimitStore } from './services/rate-limit/DORateLimitStore';
```

### 2. TypeScript Configuration

#### Worker Environment Types
```typescript
// worker-configuration.d.ts (Generated by Wrangler)
declare namespace Cloudflare {
  interface Env {
    // Authentication secrets
    GOOGLE_CLIENT_SECRET: string;
    GOOGLE_CLIENT_ID: string;
    GITHUB_CLIENT_ID: string;
    GITHUB_CLIENT_SECRET: string;
    JWT_SECRET: string;
    ENTROPY_KEY: string;
    
    // Configuration
    ENVIRONMENT: string;
    CUSTOM_DOMAIN: string;
    MAX_SANDBOX_INSTANCES: string;
    SANDBOX_INSTANCE_TYPE: string;
    
    // Service bindings
    CodeGenObject: DurableObjectNamespace<CodeGeneratorAgent>;
    Sandbox: DurableObjectNamespace<UserAppSandboxService>;
    DORateLimitStore: DurableObjectNamespace<DORateLimitStore>;
    TEMPLATES_BUCKET: R2Bucket;
    DB: D1Database;
    VibecoderStore: KVNamespace;
    AI: Ai;
    IMAGES: Cloudflare.Images;
    DISPATCHER: DispatchNamespace;
  }
}

interface Env extends Cloudflare.Env {}
```

---

## Durable Objects Patterns

### 1. Base Durable Object Structure

#### Rate Limiting Durable Object
```typescript
import { DurableObject } from 'cloudflare:workers';

export interface RateLimitBucket {
  count: number;
  timestamp: number;
}

export interface RateLimitState {
  buckets: Map<string, RateLimitBucket>;
  lastCleanup: number;
}

export interface RateLimitConfig {
  limit: number;
  period: number; // in seconds
  burst?: number;
  burstWindow?: number; // in seconds
  bucketSize?: number; // in seconds
}

/**
 * DORateLimitStore - Distributed rate limiting using Durable Objects
 * Provides better consistency and cost-effectiveness than KV-based solutions
 */
export class DORateLimitStore extends DurableObject<Env> {
  private state: RateLimitState = {
    buckets: new Map(),
    lastCleanup: Date.now()
  };
  private initialized = false;

  constructor(ctx: DurableObjectState, env: Env) {
    super(ctx, env);
  }

  async increment(key: string, config: RateLimitConfig): Promise<RateLimitResult> {
    await this.ensureInitialized();
    
    const now = Date.now();
    const bucketSize = (config.bucketSize || 10) * 1000;
    const mainWindow = config.period * 1000;
    
    // Sliding window algorithm
    const currentBucket = Math.floor(now / bucketSize) * bucketSize;
    const bucketKey = `${key}:${currentBucket}`;
    
    // Periodic cleanup
    if (now - this.state.lastCleanup > 5 * 60 * 1000) {
      await this.cleanup(now, mainWindow);
    }
    
    // Check rate limits
    const mainBuckets = this.getBucketsInWindow(key, now, mainWindow, bucketSize);
    const mainCount = mainBuckets.reduce((sum, bucket) => sum + bucket.count, 0);
    
    if (mainCount >= config.limit) {
      return { success: false, remainingLimit: 0 };
    }
    
    // Increment and persist
    const existing = this.state.buckets.get(bucketKey);
    const newCount = (existing?.count || 0) + 1;
    
    this.state.buckets.set(bucketKey, {
      count: newCount,
      timestamp: now
    });
    
    await this.ctx.storage.put(bucketKey, newCount);
    
    return { 
      success: true, 
      remainingLimit: config.limit - (mainCount + 1) 
    };
  }

  private async ensureInitialized(): Promise<void> {
    if (this.initialized) return;
    
    const stored = await this.ctx.storage.list();
    for (const [key, value] of stored) {
      if (typeof key === 'string' && typeof value === 'number') {
        this.state.buckets.set(key, {
          count: value,
          timestamp: this.extractTimestampFromKey(key)
        });
      }
    }
    
    this.initialized = true;
  }

  private getBucketsInWindow(
    key: string, 
    now: number, 
    window: number, 
    bucketSize: number
  ): RateLimitBucket[] {
    const cutoff = now - window;
    const buckets: RateLimitBucket[] = [];
    
    for (const [bucketKey, bucket] of this.state.buckets) {
      if (bucketKey.startsWith(key + ':') && bucket.timestamp > cutoff) {
        buckets.push(bucket);
      }
    }
    
    return buckets;
  }

  private async cleanup(now: number, maxAge: number): Promise<void> {
    const cutoff = now - maxAge;
    const keysToDelete: string[] = [];
    
    for (const [key, bucket] of this.state.buckets) {
      if (bucket.timestamp < cutoff) {
        keysToDelete.push(key);
      }
    }
    
    // Remove from memory and storage
    for (const key of keysToDelete) {
      this.state.buckets.delete(key);
      await this.ctx.storage.delete(key);
    }
    
    this.state.lastCleanup = now;
  }
}
```

### 2. Agent-Based Durable Objects

#### Code Generation Agent Pattern
```typescript
export interface CodeGenState {
  sessionId: string;
  sandboxInstanceId: string;
  currentPhase: string;
  status: 'generating' | 'reviewing' | 'deploying' | 'completed' | 'error';
  blueprint: BlueprintType | null;
  files: Record<string, string>;
  errors: string[];
  deploymentUrl?: string;
}

/**
 * SimpleCodeGeneratorAgent - Stateful code generation orchestrator
 * Manages the entire lifecycle of AI-powered application generation
 */
export class SimpleCodeGeneratorAgent extends Agent<Env, CodeGenState> {
  constructor(state: DurableObjectState, env: Env) {
    super(state, env);
  }

  // WebSocket handling for real-time updates
  async webSocketHandler(request: Request): Promise<Response> {
    const webSocketPair = new WebSocketPair();
    const [client, server] = Object.values(webSocketPair);

    server.accept();
    this.state.websocket = server;

    // Send current state
    if (this.state.blueprint) {
      this.sendWebSocketMessage({
        type: 'blueprint',
        data: this.state.blueprint
      });
    }

    return new Response(null, {
      status: 101,
      webSocket: client,
    });
  }

  // Generate application blueprint
  async generateBlueprint(userPrompt: string): Promise<BlueprintType> {
    this.logger().info('[GenerateBlueprint] Starting blueprint generation');
    
    const systemPrompt = this.buildBlueprintPrompt();
    const response = await this.getAIClient().chat(systemPrompt, userPrompt);
    
    const blueprint = this.parseBlueprint(response);
    this.state.blueprint = blueprint;
    
    // Send real-time update
    this.sendWebSocketMessage({
      type: 'blueprint',
      data: blueprint
    });
    
    await this.persistState();
    return blueprint;
  }

  // Phase-based code generation
  async generatePhase(phaseIndex: number): Promise<void> {
    const phase = this.state.blueprint?.phases[phaseIndex];
    if (!phase) {
      throw new Error(`Phase ${phaseIndex} not found`);
    }

    this.state.currentPhase = phase.name;
    this.state.status = 'generating';
    await this.persistState();

    // Generate files for phase
    for (const file of phase.files) {
      await this.generateFile(file, phase);
    }

    // Review and fix any issues
    await this.reviewPhase(phase);
    
    this.sendWebSocketMessage({
      type: 'phase_complete',
      data: { phaseIndex, phaseName: phase.name }
    });
  }

  // Deploy to Cloudflare Workers
  async deployToCloudflare(): Promise<{ deploymentUrl?: string; workersUrl?: string } | null> {
    try {
      this.state.status = 'deploying';
      await this.persistState();

      const deploymentResult = await this.getSandboxServiceClient()
        .deployToCloudflareWorkers(this.state.sandboxInstanceId);

      if (deploymentResult.success) {
        this.state.deploymentUrl = deploymentResult.url;
        this.state.status = 'completed';
        
        this.sendWebSocketMessage({
          type: 'deployment_success',
          data: { url: deploymentResult.url }
        });
        
        return { 
          deploymentUrl: deploymentResult.url,
          workersUrl: deploymentResult.workersUrl 
        };
      } else {
        throw new Error(deploymentResult.message);
      }
    } catch (error) {
      this.state.status = 'error';
      this.state.errors.push(error.message);
      
      this.sendWebSocketMessage({
        type: 'deployment_error',
        data: { error: error.message }
      });
      
      return null;
    } finally {
      await this.persistState();
    }
  }

  private sendWebSocketMessage(message: any): void {
    if (this.state.websocket) {
      this.state.websocket.send(JSON.stringify(message));
    }
  }
}
```

### 3. Migration Management

#### Durable Object Migrations
```jsonc
{
  "migrations": [
    {
      "new_sqlite_classes": [
        "CodeGeneratorAgent",
        "UserAppSandboxService"
      ],
      "tag": "v1"
    },
    {
      "new_sqlite_classes": [
        "DORateLimitStore"
      ],
      "tag": "v2"
    }
  ]
}
```

#### Migration Utilities
```typescript
/**
 * Merge multiple migration configurations
 */
export function mergeMigrations(migrations?: WranglerConfig['migrations']): any {
  if (!migrations || migrations.length === 0) return null;

  const merged = {
    tag: migrations[migrations.length - 1].tag, // Use latest tag
    new_classes: [] as string[],
    new_sqlite_classes: [] as string[],
    renamed_classes: [] as any[],
    deleted_classes: [] as string[]
  };

  for (const migration of migrations) {
    if (migration.new_classes) {
      merged.new_classes.push(...migration.new_classes);
    }
    if (migration.new_sqlite_classes) {
      merged.new_sqlite_classes.push(...migration.new_sqlite_classes);
    }
    if (migration.renamed_classes) {
      merged.renamed_classes.push(...migration.renamed_classes);
    }
    if (migration.deleted_classes) {
      merged.deleted_classes.push(...migration.deleted_classes);
    }
  }

  // Remove empty arrays
  Object.keys(merged).forEach(key => {
    if (Array.isArray(merged[key]) && merged[key].length === 0) {
      delete merged[key];
    }
  });

  return Object.keys(merged).length > 1 ? merged : null; // Keep tag if nothing else
}

/**
 * Extract Durable Object class names for exported handlers
 */
export function extractDurableObjectClasses(mergedMigration: any): string[] {
  const classes: string[] = [];
  
  if (mergedMigration?.new_classes) {
    classes.push(...mergedMigration.new_classes);
  }
  if (mergedMigration?.new_sqlite_classes) {
    classes.push(...mergedMigration.new_sqlite_classes);
  }
  
  return classes;
}
```

---

## Deployment Configuration

### 1. Worker Deployment API

#### CloudflareAPI Client Pattern
```typescript
/**
 * Cloudflare API client for Worker deployment operations
 */
export class CloudflareAPI {
  private baseUrl = 'https://api.cloudflare.com/client/v4';
  private accountId: string;
  private apiToken: string;

  constructor(accountId: string, apiToken: string) {
    this.accountId = accountId;
    this.apiToken = apiToken;
  }

  /**
   * Deploy a Worker script with metadata, bindings, and assets
   */
  async deployWorker(
    scriptName: string,
    metadata: WorkerMetadata,
    workerContent: string,
    dispatchNamespace?: string,
    additionalModules?: Map<string, string>,
    durableObjectClasses?: string[],
  ): Promise<void> {
    const url = dispatchNamespace
      ? `${this.baseUrl}/accounts/${this.accountId}/workers/dispatch/namespaces/${dispatchNamespace}/scripts/${scriptName}`
      : `${this.baseUrl}/accounts/${this.accountId}/workers/scripts/${scriptName}`;

    const formData = new FormData();

    // Build complete metadata with Durable Object exports
    const metadataWithExports = { ...metadata };
    if (durableObjectClasses && durableObjectClasses.length > 0) {
      metadataWithExports.exported_handlers = durableObjectClasses;
    }

    formData.append('metadata', JSON.stringify(metadataWithExports));

    // Main worker script
    const workerBlob = new Blob([workerContent], {
      type: 'application/javascript+module',
    });
    formData.append('index.js', workerBlob, 'index.js');

    // Additional modules (ES modules)
    if (additionalModules) {
      for (const [moduleName, moduleContent] of additionalModules.entries()) {
        const moduleBlob = new Blob([moduleContent], {
          type: 'application/javascript+module',
        });
        formData.append(moduleName, moduleBlob, moduleName);
      }
    }

    const response = await fetch(url, {
      method: 'PUT',
      headers: {
        Authorization: `Bearer ${this.apiToken}`,
      },
      body: formData,
    });

    if (!response.ok) {
      await this.handleDeploymentError(response, formData, url, metadataWithExports);
    }
  }

  /**
   * Handle deployment errors with automatic retry for DO migration conflicts
   */
  private async handleDeploymentError(
    response: Response,
    formData: FormData,
    url: string,
    metadata: any
  ): Promise<void> {
    const error = await response.text();
    
    try {
      const errorObj = JSON.parse(error);
      
      // Handle Durable Object migration conflicts (error code 10074)
      if (errorObj.errors?.[0]?.code === 10074) {
        const errorMessage = errorObj.errors[0].message;
        const existingClassMatch = errorMessage.match(/class '([^']+)'/);
        const existingClass = existingClassMatch ? existingClassMatch[1] : null;

        if (existingClass && metadata.migrations) {
          console.log(`‚ö†Ô∏è  Durable Object class '${existingClass}' already exists`);
          console.log('üìù Retrying deployment with filtered migrations');

          // Remove existing classes from migrations
          const migrations = { ...metadata.migrations };
          if (migrations.new_classes) {
            migrations.new_classes = migrations.new_classes.filter(
              (c: string) => c !== existingClass
            );
            if (migrations.new_classes.length === 0) delete migrations.new_classes;
          }
          if (migrations.new_sqlite_classes) {
            migrations.new_sqlite_classes = migrations.new_sqlite_classes.filter(
              (c: string) => c !== existingClass
            );
            if (migrations.new_sqlite_classes.length === 0) delete migrations.new_sqlite_classes;
          }

          // Retry with filtered migrations
          const retryFormData = new FormData();
          const updatedMetadata = { ...metadata, migrations };
          retryFormData.append('metadata', JSON.stringify(updatedMetadata));
          
          // Re-add all form data entries
          for (const [key, value] of formData.entries()) {
            if (key !== 'metadata') {
              retryFormData.append(key, value);
            }
          }

          const retryResponse = await fetch(url, {
            method: 'PUT',
            headers: { Authorization: `Bearer ${this.apiToken}` },
            body: retryFormData,
          });

          if (!retryResponse.ok) {
            const retryError = await retryResponse.text();
            throw new Error(`Retry deployment failed: ${retryError}`);
          }
          return;
        }
      }
    } catch (parseError) {
      // If JSON parsing fails, throw original error
    }

    throw new Error(`Deployment failed: ${error}`);
  }
}
```

### 2. Worker Deployer Orchestrator

#### Deployment Configuration Builder
```typescript
/**
 * Transform Wrangler config into deployment-ready configuration
 */
export function buildDeploymentConfig(
  config: WranglerConfig,
  workerContent: string,
  accountId: string,
  apiToken: string,
  assetsManifest?: Record<string, { hash: string; size: number }>,
  compatibilityFlags?: string[],
): DeployConfig {
  const hasAssets = assetsManifest && Object.keys(assetsManifest).length > 0;
  const bindings = buildWorkerBindings(config, hasAssets) as WorkerBinding[];

  return {
    accountId,
    apiToken,
    scriptName: config.name,
    compatibilityDate: config.compatibility_date,
    compatibilityFlags: compatibilityFlags || config.compatibility_flags,
    workerContent,
    assets: assetsManifest,
    bindings: bindings.length > 0 ? bindings : undefined,
    vars: config.vars,
  };
}

/**
 * Build worker bindings from Wrangler configuration
 */
export function buildWorkerBindings(
  config: any,
  hasAssets: boolean = false,
): WorkerBinding[] {
  const bindings: WorkerBinding[] = [];

  // Asset binding
  if (hasAssets) {
    bindings.push({
      name: config.assets?.binding || 'ASSETS',
      type: 'assets',
    });
  }

  // Durable Object bindings
  if (config.durable_objects?.bindings) {
    for (const binding of config.durable_objects.bindings) {
      bindings.push({
        name: binding.name,
        type: 'durable_object_namespace',
        class_name: binding.class_name,
      });
    }
  }

  // KV namespace bindings
  if (config.kv_namespaces) {
    for (const kv of config.kv_namespaces) {
      bindings.push({
        name: kv.binding,
        type: 'kv_namespace',
        namespace_id: kv.id,
      });
    }
  }

  // D1 database bindings
  if (config.d1_databases) {
    for (const db of config.d1_databases) {
      bindings.push({
        name: db.binding,
        type: 'd1',
        database_id: db.database_id,
      });
    }
  }

  // R2 bucket bindings
  if (config.r2_buckets) {
    for (const bucket of config.r2_buckets) {
      bindings.push({
        name: bucket.binding,
        type: 'r2_bucket',
        bucket_name: bucket.bucket_name,
      });
    }
  }

  return bindings;
}
```

### 3. Automated Deployment Script

#### Production Deployment Manager
```typescript
/**
 * Cloudflare Deployment Manager for production deployments
 * Handles Workers for Platforms, custom domains, and environment setup
 */
class CloudflareDeploymentManager {
  private config: WranglerConfig;
  private env: EnvironmentConfig;
  private cloudflare: Cloudflare;

  constructor() {
    this.validateEnvironment();
    this.config = this.parseWranglerConfig();
    this.extractConfigurationValues();
    this.env = this.getEnvironmentVariables();
    this.cloudflare = new Cloudflare({
      apiToken: this.env.CLOUDFLARE_API_TOKEN,
    });
    
    this.setupSignalHandlers();
  }

  /**
   * Main deployment process
   */
  async deploy(): Promise<void> {
    try {
      console.log('üöÄ Starting Cloudflare deployment...');
      
      // Step 1: Create Workers for Platforms namespace
      await this.createDispatchNamespace();
      
      // Step 2: Deploy templates to R2
      await this.deployTemplatesToR2();
      
      // Step 3: Update container configuration
      await this.updateContainerConfiguration();
      
      // Step 4: Configure domain routing
      await this.configureDomainRouting();
      
      // Step 5: Deploy the worker
      await this.deployWorker();
      
      console.log('‚úÖ Deployment completed successfully!');
      
    } catch (error) {
      console.error('‚ùå Deployment failed:', error.message);
      throw error;
    }
  }

  /**
   * Create Workers for Platforms dispatch namespace
   */
  private async createDispatchNamespace(): Promise<void> {
    const dispatchNamespace = this.env.DISPATCH_NAMESPACE;
    if (!dispatchNamespace) return;

    try {
      await this.cloudflare.workersForPlatforms.dispatch.namespaces.create({
        account_id: this.env.CLOUDFLARE_ACCOUNT_ID,
        name: dispatchNamespace,
      });
      console.log(`‚úÖ Created dispatch namespace: ${dispatchNamespace}`);
    } catch (error) {
      if (error.message?.includes('already exists')) {
        console.log(`‚ÑπÔ∏è  Dispatch namespace already exists: ${dispatchNamespace}`);
      } else {
        throw error;
      }
    }
  }

  /**
   * Deploy templates repository to R2 bucket
   */
  private async deployTemplatesToR2(): Promise<void> {
    const bucketName = 'stich-templates';
    const repoUrl = this.env.TEMPLATES_REPOSITORY;
    
    console.log(`üì¶ Deploying templates from ${repoUrl} to R2 bucket: ${bucketName}`);
    
    // Clone and prepare templates
    const tempDir = await this.cloneTemplatesRepo(repoUrl);
    
    // Upload to R2
    await this.uploadTemplatesToR2(tempDir, bucketName);
    
    console.log('‚úÖ Templates deployed to R2');
  }

  /**
   * Update wrangler configuration based on environment
   */
  private async updateWranglerConfiguration(): Promise<void> {
    const customDomain = this.env.CUSTOM_DOMAIN;
    const wranglerPath = this.getWranglerPath();
    const { content } = this.readWranglerConfig();

    let updatedContent: string;

    if (customDomain) {
      updatedContent = this.updateWranglerForCustomDomain(content, customDomain);
    } else {
      updatedContent = this.updateWranglerForWorkersDev(content);
    }

    // Update container instance limits
    updatedContent = this.updateContainerConfiguration(updatedContent);

    writeFileSync(wranglerPath, updatedContent, 'utf8');
    console.log('‚úÖ Updated wrangler.jsonc configuration');
  }

  /**
   * Deploy worker using wrangler
   */
  private async deployWorker(): Promise<void> {
    console.log('üî® Building and deploying worker...');
    
    try {
      execSync('bunx wrangler deploy --compatibility-date=2025-08-10', {
        stdio: 'inherit',
        cwd: PROJECT_ROOT,
      });
      console.log('‚úÖ Worker deployed successfully');
    } catch (error) {
      throw new DeploymentError('Worker deployment failed', error);
    }
  }
}
```

---

## Environment Management

### 1. Environment Variable Configuration

#### Production Environment Setup
```typescript
interface EnvironmentConfig {
  // Required Cloudflare credentials
  CLOUDFLARE_API_TOKEN: string;
  CLOUDFLARE_ACCOUNT_ID: string;
  
  // GitHub integration
  GITHUB_CLIENT_ID: string;
  GITHUB_CLIENT_SECRET: string;
  
  // Google OAuth
  GOOGLE_CLIENT_ID: string;
  GOOGLE_CLIENT_SECRET: string;
  
  // Security
  JWT_SECRET: string;
  ENTROPY_KEY: string;
  SECRETS_ENCRYPTION_KEY: string;
  
  // Application configuration
  TEMPLATES_REPOSITORY: string;
  CUSTOM_DOMAIN?: string;
  CUSTOM_PREVIEW_DOMAIN?: string;
  MAX_SANDBOX_INSTANCES: string;
  SANDBOX_INSTANCE_TYPE: string;
  
  // Workers for Platforms
  DISPATCH_NAMESPACE?: string;
  
  // AI Gateway
  CLOUDFLARE_AI_GATEWAY?: string;
  CLOUDFLARE_AI_GATEWAY_TOKEN?: string;
}

/**
 * Validate required environment variables
 */
function validateEnvironment(): void {
  const required = [
    'CLOUDFLARE_API_TOKEN',
    'CLOUDFLARE_ACCOUNT_ID',
    'TEMPLATES_REPOSITORY',
    'GITHUB_CLIENT_ID',
    'GITHUB_CLIENT_SECRET',
    'JWT_SECRET'
  ];

  const missing = required.filter(key => !process.env[key]);
  
  if (missing.length > 0) {
    throw new Error(`Missing required environment variables: ${missing.join(', ')}`);
  }
}
```

### 2. Configuration Management

#### Dynamic Configuration Updates
```typescript
/**
 * Update wrangler configuration for custom domain routing
 */
private updateWranglerForCustomDomain(content: string, customDomain: string): string {
  let updatedContent = content;
  
  // Update routes for custom domain
  const routes = [
    {
      pattern: customDomain,
      custom_domain: true
    },
    {
      pattern: `*${customDomain.replace(/^[^.]+\./, 'preview.')}/*`,
      custom_domain: false,
      zone_id: "db01fac4261b2604aacad8410443a3e2"
    }
  ];
  
  updatedContent = this.updateWranglerField(updatedContent, 'routes', routes);
  updatedContent = this.updateWranglerField(updatedContent, 'workers_dev', false);
  
  return updatedContent;
}

/**
 * Update container configuration with instance limits
 */
private updateContainerConfiguration(content: string): string {
  const maxInstances = parseInt(this.env.MAX_SANDBOX_INSTANCES || '10');
  const instanceType = this.env.SANDBOX_INSTANCE_TYPE || 'standard';
  
  const containers = [
    {
      class_name: "UserAppSandboxService",
      image: "./SandboxDockerfile",
      max_instances: maxInstances,
      instance_type: this.getInstanceTypeConfig(instanceType),
      rollout_step_percentage: 100
    }
  ];
  
  return this.updateWranglerField(content, 'containers', containers);
}

private getInstanceTypeConfig(type: string): any {
  const configs = {
    'standard': {
      vcpu: 4,
      memory_mib: 4096,
      disk_mb: 6144
    },
    'large': {
      vcpu: 8,
      memory_mib: 8192,
      disk_mb: 12288
    },
    'small': {
      vcpu: 2,
      memory_mib: 2048,
      disk_mb: 3072
    }
  };
  
  return configs[type] || configs['standard'];
}
```

---

## Workers for Platforms

### 1. Dispatch Namespace Management

#### Workers for Platforms Configuration
```jsonc
{
  "dispatch_namespaces": [
    {
      "binding": "DISPATCHER",
      "namespace": "vibesdk-default-namespace",
      "remote": true
    }
  ]
}
```

#### Dynamic Worker Deployment
```typescript
/**
 * Deploy user applications to Workers for Platforms
 */
export class SandboxSdkClient extends BaseSandboxService {
  async deployToCloudflareWorkers(instanceId: string): Promise<DeploymentResult> {
    try {
      // Step 1: Build the application
      const buildResult = await this.executeCommand(instanceId, 'bun run build');
      if (buildResult.exitCode !== 0) {
        throw new Error(`Build failed: ${buildResult.stderr}`);
      }

      // Step 2: Get wrangler configuration
      const wranglerConfigContent = await env.VibecoderStore.get(
        this.getWranglerKVKey(instanceId)
      );
      
      if (!wranglerConfigContent) {
        throw new Error(`Wrangler config not found for ${instanceId}`);
      }

      const config = parseWranglerConfig(wranglerConfigContent);

      // Step 3: Read compiled worker script
      const workerPath = `${instanceId}/dist/index.js`;
      const workerContent = await this.readFile(instanceId, workerPath);

      // Step 4: Deploy to dispatch namespace
      const deployConfig = buildDeploymentConfig(
        config,
        workerContent,
        env.CLOUDFLARE_ACCOUNT_ID,
        env.CLOUDFLARE_API_TOKEN
      );

      const dispatchConfig: DispatchDeployConfig = {
        ...deployConfig,
        dispatchNamespace: env.DISPATCH_NAMESPACE || 'default-namespace'
      };

      await deployWorker(dispatchConfig);

      // Step 5: Generate deployment URLs
      const workerUrl = `https://${config.name}.${env.CUSTOM_DOMAIN || 'workers.dev'}`;
      const previewUrl = `https://${config.name}.${env.CUSTOM_PREVIEW_DOMAIN || 'preview.workers.dev'}`;

      return {
        success: true,
        url: workerUrl,
        workersUrl: previewUrl,
        message: 'Deployment successful'
      };

    } catch (error) {
      this.logger.error('Deployment failed', error);
      return {
        success: false,
        message: `Deployment failed: ${error.message}`,
        error: error.message
      };
    }
  }
}
```

---

## Container Integration

### 1. Container Configuration

#### Cloudflare Container Bindings
```jsonc
{
  "containers": [
    {
      "class_name": "UserAppSandboxService",
      "image": "./SandboxDockerfile",
      "max_instances": 2900,
      "instance_type": {
        "vcpu": 4,
        "memory_mib": 4096,
        "disk_mb": 6144
      },
      "rollout_step_percentage": 100
    }
  ]
}
```

#### Dockerfile for Sandbox Containers
```dockerfile
# SandboxDockerfile
FROM node:20-alpine

# Install system dependencies
RUN apk add --no-cache \
    git \
    python3 \
    make \
    g++ \
    curl

# Install Bun
RUN curl -fsSL https://bun.sh/install | bash
ENV PATH="/root/.bun/bin:$PATH"

# Set working directory
WORKDIR /app

# Install global dependencies
RUN bun install -g wrangler@latest
RUN bun install -g @cloudflare/workers-types

# Create sandbox user
RUN adduser -D -s /bin/sh sandbox
USER sandbox

# Container will run sandbox applications
CMD ["/bin/sh"]
```

### 2. Container Lifecycle Management

#### Sandbox Service Integration
```typescript
export class UserAppSandboxService extends DurableObject<Env> {
  private containerInstance?: string;
  private instanceConfig: ContainerConfig;

  constructor(state: DurableObjectState, env: Env) {
    super(state, env);
    this.instanceConfig = this.getInstanceConfig();
  }

  /**
   * Initialize container instance for user application
   */
  async initializeContainer(): Promise<string> {
    if (this.containerInstance) {
      return this.containerInstance;
    }

    // Request container from Cloudflare Container service
    const instanceId = `sandbox-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    
    // Container will be automatically provisioned based on wrangler.jsonc config
    this.containerInstance = instanceId;
    
    // Store instance metadata
    await this.ctx.storage.put('container_instance', {
      instanceId,
      createdAt: Date.now(),
      status: 'initializing',
      config: this.instanceConfig
    });

    return instanceId;
  }

  /**
   * Execute commands in container
   */
  async executeCommand(command: string): Promise<CommandResult> {
    if (!this.containerInstance) {
      throw new Error('Container not initialized');
    }

    // Commands are executed within the container environment
    // The container has access to Node.js, Bun, Git, and Wrangler
    const result = await this.runInContainer(command);
    
    return {
      exitCode: result.exitCode,
      stdout: result.stdout,
      stderr: result.stderr,
      duration: result.duration
    };
  }

  private getInstanceConfig(): ContainerConfig {
    const instanceType = this.env.SANDBOX_INSTANCE_TYPE || 'standard';
    const maxInstances = parseInt(this.env.MAX_SANDBOX_INSTANCES || '10');

    return {
      instanceType,
      maxInstances,
      vcpu: this.getVCpuForType(instanceType),
      memoryMib: this.getMemoryForType(instanceType),
      diskMb: this.getDiskForType(instanceType)
    };
  }
}
```

---

## Service Bindings

### 1. Comprehensive Binding Configuration

#### Service Binding Patterns
```typescript
interface ServiceBindings {
  // Database services
  DB: D1Database;
  
  // Storage services  
  TEMPLATES_BUCKET: R2Bucket;
  VibecoderStore: KVNamespace;
  
  // AI and ML services
  AI: Ai;
  IMAGES: Cloudflare.Images;
  
  // Durable Objects
  CodeGenObject: DurableObjectNamespace<CodeGeneratorAgent>;
  Sandbox: DurableObjectNamespace<UserAppSandboxService>;
  DORateLimitStore: DurableObjectNamespace<DORateLimitStore>;
  
  // Workers for Platforms
  DISPATCHER: DispatchNamespace;
  
  // Rate limiting
  API_RATE_LIMITER: RateLimit;
  AUTH_RATE_LIMITER: RateLimit;
  
  // Static assets
  ASSETS: Fetcher;
  
  // Version metadata
  CF_VERSION_METADATA: WorkerVersionMetadata;
}
```

### 2. Service Integration Patterns

#### Multi-Service Orchestration
```typescript
/**
 * Service orchestration for complex workflows
 */
export class WorkflowOrchestrator {
  constructor(private env: Env) {}

  async processUserRequest(request: ProcessingRequest): Promise<ProcessingResult> {
    // Step 1: Rate limiting
    const rateLimitResult = await this.checkRateLimit(request.userId);
    if (!rateLimitResult.success) {
      throw new Error('Rate limit exceeded');
    }

    // Step 2: Initialize Durable Object agent
    const agentId = this.env.CodeGenObject.idFromName(request.sessionId);
    const agent = this.env.CodeGenObject.get(agentId);

    // Step 3: Generate application
    const blueprint = await agent.generateBlueprint(request.prompt);

    // Step 4: Initialize sandbox container
    const sandboxId = this.env.Sandbox.idFromName(request.sessionId);
    const sandbox = this.env.Sandbox.get(sandboxId);
    const instanceId = await sandbox.initializeContainer();

    // Step 5: Generate and deploy
    for (let i = 0; i < blueprint.phases.length; i++) {
      await agent.generatePhase(i);
    }

    // Step 6: Deploy to Workers for Platforms
    const deploymentResult = await sandbox.deployToCloudflareWorkers(instanceId);

    // Step 7: Store metadata in D1
    await this.env.DB.prepare(`
      INSERT INTO deployments (session_id, user_id, deployment_url, created_at)
      VALUES (?, ?, ?, ?)
    `).bind(
      request.sessionId,
      request.userId,
      deploymentResult.url,
      new Date().toISOString()
    ).run();

    return {
      success: true,
      deploymentUrl: deploymentResult.url,
      sessionId: request.sessionId
    };
  }

  private async checkRateLimit(userId: string): Promise<RateLimitResult> {
    const rateLimitId = this.env.DORateLimitStore.idFromName(`user:${userId}`);
    const rateLimiter = this.env.DORateLimitStore.get(rateLimitId);
    
    return await rateLimiter.increment(`api:${userId}`, {
      limit: 100,
      period: 3600 // 1 hour
    });
  }
}
```

---

## Development Rules

### 1. Infrastructure Best Practices

#### Durable Object Guidelines
- **Single Responsibility**: Each Durable Object should handle one specific domain
- **State Management**: Use `ctx.storage` for persistent data, memory for transient state  
- **Initialization**: Implement lazy initialization patterns for better performance
- **Cleanup**: Implement periodic cleanup for time-based data (rate limits, sessions)
- **Error Handling**: Graceful degradation when Durable Objects are unavailable

#### Worker Deployment Rules
- **Configuration Management**: Use environment variables for all configuration
- **Binding Validation**: Validate all service bindings at startup
- **Migration Strategy**: Plan Durable Object migrations carefully with backward compatibility
- **Resource Limits**: Monitor and configure appropriate resource limits for containers
- **Error Recovery**: Implement retry logic for deployment failures

#### Security Considerations
- **Secrets Management**: Use Wrangler secrets for sensitive data, never commit to code
- **Rate Limiting**: Implement multiple layers of rate limiting (global, per-user, per-endpoint)
- **Input Validation**: Validate all inputs before processing in Durable Objects
- **Access Control**: Use Cloudflare Access for admin endpoints
- **CORS Configuration**: Properly configure CORS for frontend integration

### 2. Performance Optimization

#### Worker Performance
- **Cold Start Optimization**: Minimize imports and initialization code
- **Caching Strategy**: Use appropriate caching headers for static assets
- **Database Optimization**: Use prepared statements and connection pooling for D1
- **Memory Management**: Monitor memory usage in long-running Durable Objects
- **Asset Optimization**: Compress and optimize static assets before deployment

#### Scaling Considerations
- **Durable Object Distribution**: Use consistent naming for even distribution
- **Container Scaling**: Configure appropriate instance limits based on usage patterns
- **Resource Allocation**: Monitor CPU and memory usage for container optimization
- **Geographic Distribution**: Use Cloudflare's global network for optimal performance
- **Monitoring Setup**: Implement comprehensive observability for production debugging

This infrastructure architecture provides a robust foundation for building scalable serverless applications on Cloudflare's platform with proper patterns for state management, deployment automation, and service orchestration.